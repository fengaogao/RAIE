import os
import json
import argparse
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from collections import Counter
import numpy as np


def format_item_token(mid: int) -> str:
    return f"<item_{mid}>"


def save_jsonl(path: str, rows: List[Dict]):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")


def sliding_windows(seq: List[str], win_len: int, stride: int = 1, align: str = "end"):
    """Right-aligned sliding windows used by Bert4Rec."""
    n = len(seq)
    if n < win_len:
        return
    if align == "end":
        start = (n - win_len) % stride
    else:
        start = 0

    for i in range(start, n - win_len + 1, stride):
        window = seq[i : i + win_len]
        ctx, tgt = window[:-1], window[-1]
        yield ctx, tgt, (i + win_len - 1)


def _compute_time_boundaries(ts_all: np.ndarray, quantiles: List[float]) -> List[int]:
    boundaries: List[int] = []
    prev = -1
    for q in quantiles:
        t = int(np.quantile(ts_all, q))
        if t <= prev:
            t = prev + 1
        boundaries.append(t)
        prev = t
    return boundaries


def build_examples_multi_stage(
    user2seq: Dict[int, List[Tuple[int, int]]],
    win_len: int = 10,
    stride: int = 1,
    quantiles: Optional[List[float]] = None,
):
    if not quantiles:
        quantiles = [0.4, 0.55, 0.7, 0.85, 0.95]

    ts_all = np.array([ts for pairs in user2seq.values() for _, ts in pairs], dtype=np.int64)
    assert ts_all.size > 0, "没有可用时间戳。"

    t0, t1, t2, t3, t4 = _compute_time_boundaries(ts_all, quantiles)

    stage_names = ["original", "f1", "f2", "f3", "f4", "test"]
    segments = {name: [] for name in stage_names}
    stats = {name: {"users": set(), "items": set(), "interactions": 0} for name in stage_names}
    all_items = set()

    for uid, pairs in user2seq.items():
        tss = [ts for _, ts in pairs]

        mids_o = [m for (m, ts) in pairs if ts < t0]
        tss_o = [ts for ts in tss if ts < t0]

        mids_f1 = [m for (m, ts) in pairs if t0 <= ts < t1]
        tss_f1 = [ts for ts in tss if t0 <= ts < t1]

        mids_f2 = [m for (m, ts) in pairs if t1 <= ts < t2]
        tss_f2 = [ts for ts in tss if t1 <= ts < t2]

        mids_f3 = [m for (m, ts) in pairs if t2 <= ts < t3]
        tss_f3 = [ts for ts in tss if t2 <= ts < t3]

        mids_f4 = [m for (m, ts) in pairs if t3 <= ts < t4]
        tss_f4 = [ts for ts in tss if t3 <= ts < t4]

        mids_t = [m for (m, ts) in pairs if ts >= t4]
        tss_t = [ts for ts in tss if ts >= t4]

        buckets = [
            ("original", mids_o, tss_o),
            ("f1", mids_f1, tss_f1),
            ("f2", mids_f2, tss_f2),
            ("f3", mids_f3, tss_f3),
            ("f4", mids_f4, tss_f4),
            ("test", mids_t, tss_t),
        ]

        for name, mids_seg, _ in buckets:
            if mids_seg:
                stats[name]["users"].add(uid)
                stats[name]["items"].update(mids_seg)
                stats[name]["interactions"] += len(mids_seg)

        if len(mids_o) >= win_len:
            for ctx, tgt, tgt_idx in sliding_windows(mids_o, win_len, stride, align="end"):
                ts = tss_o[tgt_idx]
                segments["original"].append(
                    {
                        "user_id": uid,
                        "timestamp": int(ts),
                        "prompt": " ".join(format_item_token(m) for m in ctx),
                        "target": format_item_token(tgt),
                    }
                )
                all_items.update(ctx)
                all_items.add(tgt)

        for name, mids_seg, tss_seg in [
            ("f1", mids_f1, tss_f1),
            ("f2", mids_f2, tss_f2),
            ("f3", mids_f3, tss_f3),
            ("f4", mids_f4, tss_f4),
            ("test", mids_t, tss_t),
        ]:
            if len(mids_seg) >= win_len:
                for ctx, tgt, tgt_idx in sliding_windows(mids_seg, win_len, stride, align="end"):
                    ts = tss_seg[tgt_idx]
                    segments[name].append(
                        {
                            "user_id": uid,
                            "timestamp": int(ts),
                            "prompt": " ".join(format_item_token(m) for m in ctx),
                            "target": format_item_token(tgt),
                        }
                    )
                    all_items.update(ctx)
                    all_items.add(tgt)

    stats_fmt = {
        name: {
            "users": len(val["users"]),
            "items": len(val["items"]),
            "interactions": val["interactions"]
        }
        for name, val in stats.items()
    }

    return {
        "segments": segments,
        "all_items": sorted(all_items),
        "boundaries": {"t0": t0, "t1": t1, "t2": t2, "t3": t3, "t4": t4},
        "stats": stats_fmt,
        "quantiles": quantiles,
    }


def save_stream(path: str, user2seq: Dict[int, List[Tuple[int, int]]], lower: int, upper: int | None):
    rows = []
    for uid, pairs in user2seq.items():
        if upper is None:
            seg = [(m, ts) for m, ts in pairs if ts >= lower]
        else:
            seg = [(m, ts) for m, ts in pairs if lower <= ts < upper]
        if len(seg) < 2:
            continue
        mids = [m for m, _ in seg]
        tss = [ts for _, ts in seg]
        rows.append(
            {
                "user_id": uid,
                "items": " ".join(format_item_token(m) for m in mids),
                "timestamps": " ".join(str(ts) for ts in tss),
            }
        )
    save_jsonl(path, rows)


def _parse_date_to_ts(s: str) -> int:
    s = s.strip()
    for fmt in ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d"):
        try:
            dt = datetime.strptime(s, fmt)
            return int(dt.timestamp())
        except ValueError:
            pass
    try:
        dt = datetime.fromisoformat(s)
        return int(dt.timestamp())
    except Exception:
        return 0


def load_yelp_reviews(review_path: str, min_stars: float = 4.0) -> Dict[int, List[Tuple[int, int]]]:
    assert os.path.exists(review_path), f"review 文件不存在: {review_path}"

    user_id_map: Dict[str, int] = {}
    biz_id_map: Dict[str, int] = {}
    next_uid, next_mid = 1, 1
    user2seq: Dict[int, List[Tuple[int, int]]] = {}

    with open(review_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                continue

            uid_s: str = obj.get("user_id", "")
            bid_s: str = obj.get("business_id", "")
            stars = obj.get("stars", None)
            date_s = obj.get("date", "")

            if uid_s == "" or bid_s == "" or stars is None:
                continue
            if float(stars) < float(min_stars):
                continue

            if uid_s not in user_id_map:
                user_id_map[uid_s] = next_uid
                next_uid += 1
            if bid_s not in biz_id_map:
                biz_id_map[bid_s] = next_mid
                next_mid += 1

            uid = user_id_map[uid_s]
            mid = biz_id_map[bid_s]
            ts = _parse_date_to_ts(date_s)
            user2seq.setdefault(uid, []).append((mid, ts))

    for u in user2seq:
        user2seq[u].sort(key=lambda x: x[1])
    return user2seq


def _find_review_file(data_dir: str) -> str:
    cand = [
        os.path.join(data_dir, "review.json"),
        os.path.join(data_dir, "yelp_academic_dataset_review.json"),
    ]
    for p in cand:
        if os.path.exists(p):
            return p
    raise FileNotFoundError(f"未找到 review.json，请检查目录：{data_dir}")


def clean_user2seq(user2seq: Dict[int, List[Tuple[int, int]]]) -> Dict[int, List[Tuple[int, int]]]:
    cleaned: Dict[int, List[Tuple[int, int]]] = {}
    for u, seq in user2seq.items():
        seq = [(m, ts) for (m, ts) in seq if ts and ts > 0]
        if not seq:
            continue
        latest = {}
        for m, ts in seq:
            if (m not in latest) or (ts > latest[m]):
                latest[m] = ts
        seq2 = [(m, ts) for m, ts in latest.items()]
        seq2.sort(key=lambda x: x[1])
        if len(seq2) >= 2:
            cleaned[u] = seq2
    return cleaned


def kcore_filter(user2seq: Dict[int, List[Tuple[int, int]]], min_user: int = 10, min_item: int = 10) -> Dict[int, List[Tuple[int, int]]]:
    u2s = {u: list(seq) for u, seq in user2seq.items()}
    changed = True
    while changed:
        changed = False
        drop_users = [u for u, seq in u2s.items() if len(seq) < min_user]
        if drop_users:
            for u in drop_users:
                del u2s[u]
            changed = True
        if not u2s:
            break

        item_cnt = Counter()
        for seq in u2s.values():
            for m, _ in seq:
                item_cnt[m] += 1
        drop_items = {m for m, c in item_cnt.items() if c < min_item}
        if drop_items:
            for u in list(u2s.keys()):
                new_seq = [(m, ts) for (m, ts) in u2s[u] if m not in drop_items]
                if not new_seq:
                    del u2s[u]
                    changed = True
                else:
                    if len(new_seq) != len(u2s[u]):
                        changed = True
                    u2s[u] = new_seq
    return u2s


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_dir", type=str, default="/home/zj/code/yelp/")
    ap.add_argument("--output_dir", type=str, default="/home/zj/code/yelp/")
    ap.add_argument("--max_len", type=int, default=10)
    ap.add_argument("--save_stream", action="store_true", default=True)
    ap.add_argument("--min_stars", type=float, default=4.0, help="评分阈值，>=该值视为正反馈")
    ap.add_argument("--min_user", type=int, default=10, help="k-core: 每个用户至少出现次数")
    ap.add_argument("--min_item", type=int, default=10, help="k-core: 每个物品至少出现次数")
    ap.add_argument("--quantiles", type=str, default="0.4,0.55,0.7,0.85,0.95", help="五个时间切分分位点")
    args = ap.parse_args()

    review_path = _find_review_file(args.data_dir)
    print(f"[Load] Yelp reviews from: {review_path}")
    user2seq_raw = load_yelp_reviews(review_path, min_stars=args.min_stars)
    n_users_raw = len(user2seq_raw)
    n_inters_raw = sum(len(s) for s in user2seq_raw.values())
    print(f"[Raw] users={n_users_raw}, interactions={n_inters_raw}")

    print("[Clean] remove ts<=0, dedup per (user,item), sort by time")
    user2seq = clean_user2seq(user2seq_raw)
    n_users_clean = len(user2seq)
    n_inters_clean = sum(len(s) for s in user2seq.values())
    item_set_clean = {m for s in user2seq.values() for (m, _) in s}
    print(f"[After Clean] users={n_users_clean}, items={len(item_set_clean)}, inter={n_inters_clean}")

    if args.min_user > 0 or args.min_item > 0:
        print(f"[K-Core] min_user={args.min_user}, min_item={args.min_item} (iterate to convergence)")
        user2seq = kcore_filter(user2seq, args.min_user, args.min_item)
        n_users = len(user2seq)
        n_inters = sum(len(s) for s in user2seq.values())
        item_set = {m for s in user2seq.values() for (m, _) in s}
        print(f"[After K-Core] users={n_users}, items={len(item_set)}, inter={n_inters}")

    quantiles = [float(x) for x in args.quantiles.split(",")]
    if len(quantiles) != 5:
        raise ValueError("quantiles must provide five comma-separated values")

    print("[Build] multi-stage examples with global time split ...")
    pack = build_examples_multi_stage(user2seq, win_len=args.max_len + 1, stride=5, quantiles=quantiles)

    print("[Block Stats]")
    for name, info in pack["stats"].items():
        print(f"{name}: users={info['users']}, items={info['items']}, interactions={info['interactions']}")

    os.makedirs(args.output_dir, exist_ok=True)
    for stage, rows in pack["segments"].items():
        save_jsonl(os.path.join(args.output_dir, f"{stage}.jsonl"), rows)

    if args.save_stream:
        t0, t1, t2, t3, t4 = (
            pack["boundaries"]["t0"],
            pack["boundaries"]["t1"],
            pack["boundaries"]["t2"],
            pack["boundaries"]["t3"],
            pack["boundaries"]["t4"],
        )
        save_stream(os.path.join(args.output_dir, "original_stream.jsonl"), user2seq, -np.inf, t0)
        save_stream(os.path.join(args.output_dir, "f1_stream.jsonl"), user2seq, t0, t1)
        save_stream(os.path.join(args.output_dir, "f2_stream.jsonl"), user2seq, t1, t2)
        save_stream(os.path.join(args.output_dir, "f3_stream.jsonl"), user2seq, t2, t3)
        save_stream(os.path.join(args.output_dir, "f4_stream.jsonl"), user2seq, t3, t4)
        save_stream(os.path.join(args.output_dir, "test_stream.jsonl"), user2seq, t4, None)

    with open(os.path.join(args.output_dir, "item_ids.json"), "w", encoding="utf-8") as f:
        json.dump({"item_ids": pack["all_items"]}, f, ensure_ascii=False)

    with open(os.path.join(args.output_dir, "meta.json"), "w", encoding="utf-8") as f:
        json.dump(
            {
                "counts": {stage: len(rows) for stage, rows in pack["segments"].items()},
                "num_items": len(pack["all_items"]),
                "boundaries": pack["boundaries"],
                "quantiles": quantiles,
                "schema": {"prompt": "str", "target": "str", "user_id": "int", "timestamp": "int"},
                "preprocess": {"min_stars": args.min_stars, "kcore": {"min_user": args.min_user, "min_item": args.min_item}},
            },
            f,
            ensure_ascii=False,
            indent=2,
        )


if __name__ == "__main__":
    main()
