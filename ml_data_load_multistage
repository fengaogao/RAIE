import os
import json
import argparse
from typing import Dict, List, Tuple, Optional
import numpy as np


def format_item_token(mid: int) -> str:
    return f"<item_{mid}>"


def save_jsonl(path: str, rows: List[Dict]):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")


def load_mlm1m_ratings(ratings_path: str) -> Dict[int, List[Tuple[int, int]]]:
    """Load MovieLens-10M ratings and keep ratings >= 4.0."""
    user2seq: Dict[int, List[Tuple[int, int]]] = {}
    with open(ratings_path, "r", encoding="latin-1") as f:
        for line in f:
            parts = line.strip().split("::")
            if len(parts) != 4:
                continue
            uid = int(parts[0])
            mid = int(parts[1])
            rating = float(parts[2])
            ts = int(parts[3])
            if rating >= 4.0:
                user2seq.setdefault(uid, []).append((mid, ts))

    for u in user2seq:
        user2seq[u].sort(key=lambda x: x[1])
    return user2seq


def sliding_windows(seq: List[str], win_len: int, stride: int = 1, align: str = "end"):
    """Right-aligned sliding windows used by Bert4Rec."""
    n = len(seq)
    if n < win_len:
        return
    if align == "end":
        start = (n - win_len) % stride
    else:
        start = 0

    for i in range(start, n - win_len + 1, stride):
        window = seq[i : i + win_len]
        ctx, tgt = window[:-1], window[-1]
        yield ctx, tgt, (i + win_len - 1)


def _compute_time_boundaries(ts_all: np.ndarray, quantiles: List[float]) -> List[int]:
    """Compute strictly increasing timestamp cut points from quantiles."""
    boundaries: List[int] = []
    prev = -1
    for q in quantiles:
        t = int(np.quantile(ts_all, q))
        if t <= prev:
            t = prev + 1
        boundaries.append(t)
        prev = t
    return boundaries


def build_examples_multi_stage(
    user2seq: Dict[int, List[Tuple[int, int]]],
    win_len: int = 10,
    stride: int = 1,
    quantiles: Optional[List[float]] = None,
):
    """
    Split global timeline into Original + four finetune buckets + Test.

    quantiles controls boundaries: [q0, q1, q2, q3, q4] ->
        original: ts < t0
        f1: t0 <= ts < t1
        f2: t1 <= ts < t2
        f3: t2 <= ts < t3
        f4: t3 <= ts < t4
        test: ts >= t4
    """

    if not quantiles:
        # Balanced front-loading for long-tail data
        quantiles = [0.4, 0.55, 0.7, 0.85, 0.95]

    ts_all = np.array([ts for pairs in user2seq.values() for _, ts in pairs], dtype=np.int64)
    assert ts_all.size > 0, "没有可用时间戳。"

    boundaries = _compute_time_boundaries(ts_all, quantiles)
    t0, t1, t2, t3, t4 = boundaries

    stage_names = ["original", "f1", "f2", "f3", "f4", "test"]
    segments = {name: [] for name in stage_names}
    original_stride1: List[Dict] = []
    stats = {name: {"users": set(), "items": set(), "interactions": 0} for name in stage_names}
    all_items = set()

    for uid, pairs in user2seq.items():
        mids = [m for m, _ in pairs]
        tss = [ts for _, ts in pairs]

        mids_o = [m for (m, ts) in pairs if ts < t0]
        tss_o = [ts for ts in tss if ts < t0]

        mids_f1 = [m for (m, ts) in pairs if t0 <= ts < t1]
        tss_f1 = [ts for ts in tss if t0 <= ts < t1]

        mids_f2 = [m for (m, ts) in pairs if t1 <= ts < t2]
        tss_f2 = [ts for ts in tss if t1 <= ts < t2]

        mids_f3 = [m for (m, ts) in pairs if t2 <= ts < t3]
        tss_f3 = [ts for ts in tss if t2 <= ts < t3]

        mids_f4 = [m for (m, ts) in pairs if t3 <= ts < t4]
        tss_f4 = [ts for ts in tss if t3 <= ts < t4]

        mids_t = [m for (m, ts) in pairs if ts >= t4]
        tss_t = [ts for ts in tss if ts >= t4]

        buckets = [
            ("original", mids_o, tss_o),
            ("f1", mids_f1, tss_f1),
            ("f2", mids_f2, tss_f2),
            ("f3", mids_f3, tss_f3),
            ("f4", mids_f4, tss_f4),
            ("test", mids_t, tss_t),
        ]

        for name, mids_seg, _ in buckets:
            if mids_seg:
                stats[name]["users"].add(uid)
                stats[name]["items"].update(mids_seg)
                stats[name]["interactions"] += len(mids_seg)

        if len(mids_o) >= win_len:
            for ctx, tgt, tgt_idx in sliding_windows(mids_o, win_len, stride, align="end"):
                ts = tss_o[tgt_idx]
                segments["original"].append(
                    {
                        "user_id": uid,
                        "timestamp": int(ts),
                        "prompt": " ".join(format_item_token(m) for m in ctx),
                        "target": format_item_token(tgt),
                    }
                )
                all_items.update(ctx)
                all_items.add(tgt)

            for ctx, tgt, tgt_idx in sliding_windows(mids_o, win_len, 1, align="end"):
                ts = tss_o[tgt_idx]
                original_stride1.append(
                    {
                        "user_id": uid,
                        "timestamp": int(ts),
                        "prompt": " ".join(format_item_token(m) for m in ctx),
                        "target": format_item_token(tgt),
                    }
                )
                all_items.update(ctx)
                all_items.add(tgt)

        for name, mids_seg, tss_seg in [
            ("f1", mids_f1, tss_f1),
            ("f2", mids_f2, tss_f2),
            ("f3", mids_f3, tss_f3),
            ("f4", mids_f4, tss_f4),
            ("test", mids_t, tss_t),
        ]:
            if len(mids_seg) >= win_len:
                for ctx, tgt, tgt_idx in sliding_windows(mids_seg, win_len, stride, align="end"):
                    ts = tss_seg[tgt_idx]
                    segments[name].append(
                        {
                            "user_id": uid,
                            "timestamp": int(ts),
                            "prompt": " ".join(format_item_token(m) for m in ctx),
                            "target": format_item_token(tgt),
                        }
                    )
                    all_items.update(ctx)
                    all_items.add(tgt)

    stats_fmt = {
        name: {
            "users": len(val["users"]),
            "items": len(val["items"]),
            "interactions": val["interactions"],
        }
        for name, val in stats.items()
    }

    return {
        "segments": segments,
        "all_items": sorted(all_items),
        "boundaries": {"t0": t0, "t1": t1, "t2": t2, "t3": t3, "t4": t4},
        "stats": stats_fmt,
        "quantiles": quantiles,
        "original_stride1": original_stride1,
    }


def save_stream(path: str, user2seq: Dict[int, List[Tuple[int, int]]], lower: int, upper: int | None):
    """Save user sequences filtered by [lower, upper) timestamps for streaming use."""
    rows = []
    for uid, pairs in user2seq.items():
        if upper is None:
            seg = [(m, ts) for m, ts in pairs if ts >= lower]
        else:
            seg = [(m, ts) for m, ts in pairs if lower <= ts < upper]
        if len(seg) < 2:
            continue
        mids = [m for m, _ in seg]
        tss = [ts for _, ts in seg]
        rows.append(
            {
                "user_id": uid,
                "items": " ".join(format_item_token(m) for m in mids),
                "timestamps": " ".join(str(ts) for ts in tss),
            }
        )
    save_jsonl(path, rows)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", type=str, default="/home/zj/code/ml-10M100K/")
    parser.add_argument("--output_dir", type=str, default="/home/zj/code/ml-10M100K/")
    parser.add_argument("--max_len", type=int, default=10)
    parser.add_argument(
        "--quantiles",
        type=str,
        default="0.4,0.55,0.7,0.85,0.95",
        help="five quantiles for t0-t4 split",
    )
    parser.add_argument("--save_stream", action="store_true", default=True)
    args = parser.parse_args()

    ratings_path = os.path.join(args.data_dir, "ratings.dat")
    if not os.path.exists(ratings_path):
        raise FileNotFoundError(ratings_path)

    quantiles = [float(x) for x in args.quantiles.split(",")]
    if len(quantiles) != 5:
        raise ValueError("quantiles must provide five comma-separated values")

    print("Loading MovieLens ...")
    user2seq = load_mlm1m_ratings(ratings_path)

    print("Building multi-stage examples ...")
    pack = build_examples_multi_stage(user2seq, win_len=args.max_len + 1, stride=5, quantiles=quantiles)

    for name, info in pack["stats"].items():
        print(f"{name}: users={info['users']}, items={info['items']}, interactions={info['interactions']}")

    os.makedirs(args.output_dir, exist_ok=True)

    for stage, rows in pack["segments"].items():
        save_jsonl(os.path.join(args.output_dir, f"{stage}.jsonl"), rows)
    save_jsonl(os.path.join(args.output_dir, "original_stride1.jsonl"), pack["original_stride1"])

    if args.save_stream:
        t0, t1, t2, t3, t4 = (
            pack["boundaries"]["t0"],
            pack["boundaries"]["t1"],
            pack["boundaries"]["t2"],
            pack["boundaries"]["t3"],
            pack["boundaries"]["t4"],
        )
        save_stream(os.path.join(args.output_dir, "original_stream.jsonl"), user2seq, -np.inf, t0)
        save_stream(os.path.join(args.output_dir, "f1_stream.jsonl"), user2seq, t0, t1)
        save_stream(os.path.join(args.output_dir, "f2_stream.jsonl"), user2seq, t1, t2)
        save_stream(os.path.join(args.output_dir, "f3_stream.jsonl"), user2seq, t2, t3)
        save_stream(os.path.join(args.output_dir, "f4_stream.jsonl"), user2seq, t3, t4)
        save_stream(os.path.join(args.output_dir, "test_stream.jsonl"), user2seq, t4, None)

    with open(os.path.join(args.output_dir, "item_ids.json"), "w", encoding="utf-8") as f:
        json.dump({"item_ids": pack["all_items"]}, f, ensure_ascii=False)

    with open(os.path.join(args.output_dir, "meta.json"), "w", encoding="utf-8") as f:
        json.dump(
            {
                "counts": {
                    **{stage: len(rows) for stage, rows in pack["segments"].items()},
                    "original_stride1": len(pack["original_stride1"]),
                },
                "num_items": len(pack["all_items"]),
                "boundaries": pack["boundaries"],
                "quantiles": quantiles,
                "schema": {"prompt": "str", "target": "str", "user_id": "int", "timestamp": "int"},
            },
            f,
            ensure_ascii=False,
            indent=2,
        )


if __name__ == "__main__":
    main()
