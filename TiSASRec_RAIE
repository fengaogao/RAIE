import os
import json
import math
import argparse
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset
from torch.nn.utils import clip_grad_norm_

# ---- NEW: PEFT / LoRA ----
try:
    from peft import LoraConfig, get_peft_model, TaskType
    PEFT_AVAILABLE = True
except Exception as e:
    PEFT_AVAILABLE = False
    _PEFT_ERR = e

# ------------------------------
# Utils
# ------------------------------

def set_seed(seed: int = 42):
    import random
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)


def read_jsonl(path: str) -> List[dict]:
    rows = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            rows.append(json.loads(line))
    return rows


def load_item_vocab(data_dir: str):
    item_json = os.path.join(data_dir, 'item_ids.json')
    with open(item_json, 'r', encoding='utf-8') as f:
        obj = json.load(f)
    item_ids: List[int] = obj['item_ids']

    specials = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']
    token2id = {tok: i for i, tok in enumerate(specials)}
    id2token = specials.copy()

    for mid in sorted(item_ids):
        tok = f"<item_{mid}>"
        token2id[tok] = len(id2token)
        id2token.append(tok)

    item_token_ids = list(range(len(specials), len(id2token)))
    return token2id, id2token, item_token_ids


# ------------------------------
# Time bucketizer (TiSASRec)
# ------------------------------

class TimeBucketizer:
    """Log-scale bucketization of time intervals."""
    def __init__(self, time_unit: str = 'seconds', n_buckets: int = 64, clamp_days: Optional[int] = 60):
        if time_unit == 'seconds': self.unit = 1
        elif time_unit == 'minutes': self.unit = 60
        elif time_unit == 'hours': self.unit = 3600
        elif time_unit == 'days': self.unit = 86400
        else: raise ValueError('time_unit must be seconds|minutes|hours|days')
        self.n_buckets = n_buckets
        self.clamp_sec = None if clamp_days is None else clamp_days * 86400

    def bucketize(self, t_diff: np.ndarray) -> np.ndarray:
        if self.clamp_sec is not None:
            t_diff = np.minimum(t_diff, self.clamp_sec)
        x = t_diff.astype(np.float64) / float(self.unit)
        out = np.zeros_like(x, dtype=np.int64)
        mask = x > 0
        out[mask] = 1 + np.floor(np.log2(np.maximum(x[mask], 1.0))).astype(np.int64)
        out = np.clip(out, 0, self.n_buckets - 1)
        return out


# ------------------------------
# Dataset
# ------------------------------

@dataclass
class Example:
    prompt_tokens: List[str]
    target_token: str
    prompt_ts: Optional[List[int]]  # optional per-token timestamps


class SeqDataset(Dataset):
    # 测试/微调：从 finetune.jsonl / test.jsonl 读取 prompt/target/prompt_ts
    def __init__(self, jsonl_path: str):
        rows = read_jsonl(jsonl_path)
        self.examples: List[Example] = []
        for r in rows:
            prompt = (r.get('prompt') or '').strip()
            target = (r.get('target') or '').strip()
            if not prompt or not target:
                continue
            ptoks = prompt.split()
            pts = None
            if 'prompt_ts' in r and isinstance(r['prompt_ts'], str):
                try:
                    pts = [int(x) for x in r['prompt_ts'].strip().split()]
                    if len(pts) != len(ptoks):
                        pts = None
                except Exception:
                    pts = None
            self.examples.append(Example(ptoks, target, pts))

    def __len__(self): return len(self.examples)
    def __getitem__(self, idx: int) -> Example: return self.examples[idx]


class StreamPairDataset(Dataset):
    """
    O阶段训练：original_stream.jsonl（每行一位用户完整序列），
    在线滑窗生成 (prompt -> target) 样本。
    每行格式例：
      {"user_id": ..., "items": "<item_a> <item_b> ...", "timestamps": "t_a t_b ..."}  # timestamps 可缺省
    """
    def __init__(self, jsonl_path: str, stride: int = 1, min_ctx: int = 1):
        rows = read_jsonl(jsonl_path)
        self.examples: List[Example] = []

        for r in rows:
            items_str = (r.get('items') or '').strip()
            if not items_str:
                continue
            toks = items_str.split()

            ts = None
            ts_str = (r.get('timestamps') or '').strip()
            if ts_str:
                try:
                    ts = [int(x) for x in ts_str.split()]
                    if len(ts) != len(toks):
                        ts = None
                except Exception:
                    ts = None

            for t in range(1, len(toks), stride):
                prompt = toks[:t]
                if len(prompt) < min_ctx:
                    continue
                target = toks[t]
                pts = ts[:t] if ts is not None else None
                self.examples.append(Example(prompt, target, pts))

    def __len__(self): return len(self.examples)
    def __getitem__(self, idx: int) -> Example: return self.examples[idx]



class Collator:
    def __init__(self, token2id: Dict[str, int], max_len: int, pad_id: int,
                 time_bucketizer: TimeBucketizer, item_token_ids: List[int]):
        self.tok2id = token2id
        self.max_len = max_len
        self.pad_id = pad_id
        self.tb = time_bucketizer
        self.item_id_set = set(item_token_ids)

    def _enc(self, t: str) -> int:
        return self.tok2id.get(t, self.tok2id['[UNK]'])

    def __call__(self, batch: List[Example]):
        B = len(batch); L = self.max_len
        seq = torch.full((B, L), self.pad_id, dtype=torch.long)
        ts = torch.zeros((B, L), dtype=torch.long)
        labels = torch.full((B,), -100, dtype=torch.long)       # ignore by default
        seqlen = torch.zeros((B,), dtype=torch.long)

        for i, ex in enumerate(batch):
            ids = [self._enc(t) for t in ex.prompt_tokens[-L:]]
            l = len(ids)
            seq[i, :l] = torch.tensor(ids, dtype=torch.long)
            seqlen[i] = l
            lab = self._enc(ex.target_token)
            labels[i] = lab if lab in self.item_id_set else -100  # 只接收 item 目标

            if ex.prompt_ts is not None:
                tlist = ex.prompt_ts[-L:]
                ts[i, :l] = torch.tensor(tlist if len(tlist)==l else list(range(1, l+1)), dtype=torch.long)
            else:
                ts[i, :l] = torch.arange(1, l+1, dtype=torch.long)

        t_np = ts.numpy()
        t_diff = np.abs(t_np[:, :, None] - t_np[:, None, :])
        t_bk = torch.from_numpy(np.stack([self.tb.bucketize(t_diff[b]) for b in range(B)], axis=0).astype(np.int64))

        valid = (seq != self.pad_id)
        key_mask = valid.unsqueeze(1).unsqueeze(2)
        causal = torch.tril(torch.ones((L, L), dtype=torch.bool)).unsqueeze(0).unsqueeze(1)
        attn_mask = key_mask & causal

        return {'seq': seq, 'ts': ts, 't_buckets': t_bk, 'attn_mask': attn_mask, 'labels': labels, 'seqlen': seqlen}



# ------------------------------
# TiSASRec Blocks
# ------------------------------

class TiSASRecLayer(nn.Module):
    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float,
                 max_rel_pos: int, n_time_buckets: int):
        super().__init__()
        assert d_model % n_heads == 0
        self.h = n_heads
        self.d = d_model // n_heads

        self.Wq = nn.Linear(d_model, d_model)
        self.Wk = nn.Linear(d_model, d_model)
        self.Wv = nn.Linear(d_model, d_model)
        self.Wo = nn.Linear(d_model, d_model)

        # Relative position & time-interval embeddings for K and V (shared across heads)
        self.pos_k = nn.Embedding(max_rel_pos, self.d)
        self.pos_v = nn.Embedding(max_rel_pos, self.d)
        self.tim_k = nn.Embedding(n_time_buckets, self.d)
        self.tim_v = nn.Embedding(n_time_buckets, self.d)

        self.attn_drop = nn.Dropout(dropout)
        self.proj_drop = nn.Dropout(dropout)

        self.ln1 = nn.LayerNorm(d_model)
        self.ln2 = nn.LayerNorm(d_model)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout),
            nn.Linear(d_ff, d_model), nn.Dropout(dropout)
        )

        # init
        nn.init.xavier_uniform_(self.pos_k.weight)
        nn.init.xavier_uniform_(self.pos_v.weight)
        nn.init.xavier_uniform_(self.tim_k.weight)
        nn.init.xavier_uniform_(self.tim_v.weight)

    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor,
                rel_pos: torch.Tensor, t_buckets: torch.Tensor) -> torch.Tensor:
        """
        x: (B,L,d_model)
        attn_mask: (B,1,L,L) boolean mask
        rel_pos: (L,L) ints in [0, max_rel_pos)
        t_buckets: (B,L,L) ints in [0, n_time_buckets)
        """
        B, L, D = x.size()
        h, d = self.h, self.d

        q = self.Wq(x).view(B, L, h, d).transpose(1, 2)  # (B,h,L,d)
        k = self.Wk(x).view(B, L, h, d).transpose(1, 2)  # (B,h,L,d)
        v = self.Wv(x).view(B, L, h, d).transpose(1, 2)  # (B,h,L,d)

        # Pairwise embeddings
        pos_k = self.pos_k(rel_pos).unsqueeze(0).unsqueeze(0)         # (1,1,L,L,d)
        pos_v = self.pos_v(rel_pos).unsqueeze(0).unsqueeze(0)         # (1,1,L,L,d)
        tim_k = self.tim_k(t_buckets).unsqueeze(1)  #  (B,1,L,L,d)
        tim_v = self.tim_v(t_buckets).unsqueeze(1)  # (B,1,L,L,d)

        # Broadcast to (B,h,L,L,d)
        pos_k = pos_k.expand(B, h, L, L, d)
        pos_v = pos_v.expand(B, h, L, L, d)
        tim_k = tim_k.expand(B, h, L, L, d)
        tim_v = tim_v.expand(B, h, L, L, d)

        # Add pairwise terms to K and V
        k_exp = k.unsqueeze(3) + pos_k + tim_k    # (B,h,L,L,d)
        v_exp = v.unsqueeze(3) + pos_v + tim_v    # (B,h,L,L,d)

        # Attention logits
        logits = (q.unsqueeze(3) * k_exp).sum(-1) / math.sqrt(d)
        mask = attn_mask  # (B,1,L,L) bool
        logits = logits.masked_fill(~mask, float('-inf'))

        m = mask.expand(B, h, L, L)  # (B,h,L,L)
        row_has_any = m.any(dim=-1, keepdim=True)  # (B,h,L,1)
        logits = torch.where(row_has_any, logits, torch.zeros_like(logits))

        attn = torch.softmax(logits, dim=-1)
        attn = self.attn_drop(attn)

        # context = sum_j attn_ij * (V_j + ...)
        ctx = (attn.unsqueeze(-1) * v_exp).sum(dim=3)  # (B,h,L,d)
        ctx = ctx.transpose(1, 2).contiguous().view(B, L, D)
        out = self.proj_drop(self.Wo(ctx))

        # FFN
        x = self.ln1(x + out)
        x2 = self.ffn(x)
        x = self.ln2(x + x2)
        return x


class TiSASRec(nn.Module):
    def __init__(self, n_items: int, d_model: int = 256, n_layers: int = 2,
                 n_heads: int = 4, d_ff: int = 1024, dropout: float = 0.2,
                 max_len: int = 50, n_time_buckets: int = 64):
        super().__init__()
        self.n_items = n_items
        self.max_len = max_len
        self.pad_id = 0  # we will pass the actual pad id to forward for mask

        self.item_emb = nn.Embedding(n_items, d_model, padding_idx=0)
        nn.init.normal_(self.item_emb.weight, mean=0.0, std=0.02)
        self.pos_emb = nn.Embedding(max_len, d_model)
        nn.init.normal_(self.pos_emb.weight, mean=0.0, std=0.02)
        self.dropout = nn.Dropout(dropout)
        self.layers = nn.ModuleList([
            TiSASRecLayer(d_model, n_heads, d_ff, dropout,
                           max_rel_pos=max_len, n_time_buckets=n_time_buckets)
            for _ in range(n_layers)
        ])
        self.norm = nn.LayerNorm(d_model)

        # Output projection will tie with item_emb
        self.out_bias = nn.Parameter(torch.zeros(n_items))

    def forward(
        self,
        seq_ids: torch.Tensor = None,
        attn_mask: torch.Tensor = None,
        t_buckets: torch.Tensor = None,
        pad_id: int = None,
        *,
        input_ids: torch.Tensor = None,
        attention_mask: torch.Tensor = None,
        time_buckets: torch.Tensor = None,
        **kwargs,
    ) -> torch.Tensor:
        x_ids = input_ids if input_ids is not None else seq_ids
        if x_ids is None:
            raise ValueError("TiSASRec.forward expects `seq_ids` or `input_ids`")

        if t_buckets is None and time_buckets is not None:
            t_buckets = time_buckets

        if pad_id is None:
            pad_id = self.item_emb.padding_idx if self.item_emb.padding_idx is not None else 0
        self.item_emb.padding_idx = pad_id

        B, L = x_ids.size()
        device = x_ids.device

        if attn_mask is None:
            if attention_mask is not None:
                am = attention_mask
                if am.dtype != torch.bool:
                    am = am != 0
                if am.dim() == 2:
                    causal = torch.tril(torch.ones((L, L), dtype=torch.bool, device=device))
                    qmask = am.unsqueeze(1).unsqueeze(3).expand(B, 1, L, L)
                    kmask = am.unsqueeze(1).unsqueeze(2).expand(B, 1, L, L)
                    attn_mask = (qmask & kmask) & causal.unsqueeze(0).unsqueeze(0)
                elif am.dim() == 4:
                    attn_mask = am
                else:
                    raise ValueError(f"attention_mask must be (B,L) or (B,1,L,L), got {am.shape}")
            else:
                valid = (x_ids != pad_id)
                causal = torch.tril(torch.ones((L, L), dtype=torch.bool, device=device))
                qmask = valid.unsqueeze(1).unsqueeze(3).expand(B, 1, L, L)
                kmask = valid.unsqueeze(1).unsqueeze(2).expand(B, 1, L, L)
                attn_mask = (qmask & kmask) & causal.unsqueeze(0).unsqueeze(0)
        else:
            if attn_mask.dtype != torch.bool:
                attn_mask = attn_mask.bool()

        if t_buckets is None:
            t_buckets = torch.zeros((B, L, L), dtype=torch.long, device=device)

        x = self.item_emb(x_ids)
        pos_idx = torch.arange(L, device=device).unsqueeze(0).expand(B, L)
        x = self.dropout(x + self.pos_emb(pos_idx))

        idxs = torch.arange(L, device=device)
        rel = idxs.view(-1, 1) - idxs.view(1, -1)
        rel = torch.clamp(rel, min=0, max=L-1)

        for layer in self.layers:
            x = layer(x, attn_mask, rel, t_buckets)

        return self.norm(x)

    def predict_last(self, h: torch.Tensor, seqlen: torch.Tensor) -> torch.Tensor:
        B, L, D = h.size()
        idx = (seqlen - 1).clamp(min=0)
        rows = torch.arange(B, device=h.device)
        last_h = h[rows, idx, :]  # (B,D)
        logits = last_h @ self.item_emb.weight.t() + self.out_bias  # (B,V)
        return logits


# ------------------------------
# Metrics & Training
# ------------------------------

def recall_ndcg_sums(logits: torch.Tensor, labels: torch.Tensor,
                      item_token_ids: List[int], topk=(5,10,20)):
    device = logits.device
    V = logits.size(1)
    mask = torch.full((V,), float('-inf'), device=device)
    mask[item_token_ids] = 0.0
    logits = logits + mask

    max_k = max(topk)
    _, idx = torch.topk(logits, k=max_k, dim=1)

    lab = labels.view(-1,1).expand(-1, max_k)
    match = (idx == lab).float()

    out = {k:{'hit':0.0,'dcg':0.0} for k in topk}
    for K in topk:
        mK = match[:,:K]
        hit = mK.max(dim=1).values
        pos = torch.argmax(mK, dim=1)
        dcg = hit * (1.0/torch.log2(pos.float()+2.0))
        out[K]['hit'] += float(hit.sum().item())
        out[K]['dcg'] += float(dcg.sum().item())
    return out, labels.size(0)


def aggregate_metrics(sum_dict, N, topk=(5,10,20)):
    res = {}
    for K in topk:
        res[f'Recall@{K}'] = sum_dict[K]['hit']/max(N,1)
        res[f'NDCG@{K}'] = sum_dict[K]['dcg']/max(N,1)
    return res


class ReplayBuffer:
    """Wrap O-stage DataLoader to iterate forever."""
    def __init__(self, base_dataset: Dataset, collate_fn, batch_size: int):
        self.loader = DataLoader(base_dataset, batch_size=batch_size, shuffle=True,
                                 num_workers=0, collate_fn=collate_fn)
        self.it = iter(self.loader)
    def next_batch(self):
        try:
            return next(self.it)
        except StopIteration:
            self.it = iter(self.loader)
            return next(self.it)

@torch.no_grad()
def _clone_params(model: nn.Module):
    return {n: p.detach().clone() for n,p in model.named_parameters() if p.requires_grad}

def _masked_item_logits(logits: torch.Tensor, item_token_ids: List[int]) -> torch.Tensor:
    V = logits.size(1)
    mask_vec = torch.full((V,), float('-inf'), device=logits.device)
    mask_vec[item_token_ids] = 0.0
    return logits + mask_vec

def compute_fisher_diag_tisasrec(model: TiSASRec, loader: DataLoader, device,
                                 pad_id: int, item_token_ids: List[int], max_batches: int = 100):
    model.eval()
    fisher = {n: torch.zeros_like(p, device=device) for n,p in model.named_parameters() if p.requires_grad}
    n_batches = 0
    for batch in loader:
        seq = batch['seq'].to(device)
        t_bk = batch['t_buckets'].to(device)
        attn_mask = batch['attn_mask'].to(device)
        labels = batch['labels'].to(device)
        seqlen = batch['seqlen'].to(device)

        model.zero_grad(set_to_none=True)
        h = model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=pad_id)
        logits = model.predict_last(h, seqlen)
        logits = _masked_item_logits(logits, item_token_ids)
        loss = F.cross_entropy(logits, labels, ignore_index=-100)
        loss.backward()

        for n,p in model.named_parameters():
            if p.requires_grad and p.grad is not None:
                fisher[n] += (p.grad.detach() ** 2)
        n_batches += 1
        if n_batches >= max_batches: break
    for n in fisher:
        fisher[n] /= max(1, n_batches)
    model.zero_grad(set_to_none=True)
    return fisher

def ewc_loss(model: nn.Module, fisher: Dict[str, torch.Tensor],
             prev_params: Dict[str, torch.Tensor], lam: float):
    reg = 0.0
    for n,p in model.named_parameters():
        if p.requires_grad and (n in fisher):
            reg = reg + (fisher[n] * (p - prev_params[n])**2).sum()
    return lam * reg

def _sample_negatives_for_batch(seq: torch.Tensor, labels: torch.Tensor,
                                item_token_ids: List[int], pad_id: int) -> torch.Tensor:
    """Sample one negative per row, not in context and != label."""
    device = seq.device
    item_set = set(int(x) for x in item_token_ids)
    B, L = seq.shape
    neg = torch.empty(B, dtype=torch.long, device=device)
    for i in range(B):
        ctx = [int(x) for x in seq[i].tolist() if (x != pad_id and x in item_set)]
        tgt = int(labels[i].item())
        deny = set(ctx); deny.add(tgt)
        while True:
            cand = int(item_token_ids[np.random.randint(0, len(item_token_ids))])
            if cand not in deny:
                neg[i] = cand; break
    return neg

def lwf_kd_loss_tisasrec(student: nn.Module, teacher: TiSASRec,
                         batch: dict, pad_id: int,
                         item_token_ids: List[int], T: float=2.0, alpha: float=0.5):
    seq = batch['seq']; t_bk = batch['t_buckets']; attn_mask = batch['attn_mask']
    labels = batch['labels']; seqlen = batch['seqlen']
    device = seq.device

    with torch.no_grad():
        h_t = teacher(seq, attn_mask, t_bk, pad_id)
        logits_t = teacher.predict_last(h_t, seqlen) / T
        logits_t = _masked_item_logits(logits_t, item_token_ids)

    neg_ids = _sample_negatives_for_batch(seq, labels, item_token_ids, pad_id)
    rows = torch.arange(seq.size(0), device=device)
    cand = torch.stack([labels, neg_ids], dim=1)           # [B,2]

    t_cand = logits_t.gather(1, cand)                      # [B,2]
    t_probs = F.softmax(t_cand, dim=-1)

    h_s = student(seq, attn_mask, t_bk, pad_id)
    logits_s = student.predict_last(h_s, seqlen) / T
    logits_s = _masked_item_logits(logits_s, item_token_ids)
    s_cand = logits_s.gather(1, cand)                      # [B,2]
    s_log_probs = F.log_softmax(s_cand, dim=-1)

    kd = F.kl_div(s_log_probs, t_probs, reduction='batchmean') * (T*T)
    return alpha * kd

def train_one_epoch(model: TiSASRec, loader: DataLoader, optimizer, scheduler,
                    device, pad_id, item_token_ids, grad_clip: float):
    model.train()
    losses = []
    for batch in tqdm(loader, desc='Train(O)', leave=False):
        seq = batch['seq'].to(device)
        t_bk = batch['t_buckets'].to(device)
        attn_mask = batch['attn_mask'].to(device)
        labels = batch['labels'].to(device)
        seqlen = batch['seqlen'].to(device)

        h = model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=pad_id)
        logits = model.predict_last(h, seqlen)
        logits = _masked_item_logits(logits, item_token_ids)
        loss = F.cross_entropy(logits, labels, ignore_index=-100)

        optimizer.zero_grad(set_to_none=True); loss.backward()
        if grad_clip and grad_clip > 0: clip_grad_norm_(model.parameters(), grad_clip)
        optimizer.step(); scheduler.step()
        losses.append(float(loss.detach().item()))
    return np.mean(losses) if losses else 0.0


def finetune_one_epoch(model: nn.Module, ft_loader: DataLoader, optimizer, scheduler,
                       device, pad_id, item_token_ids, grad_clip: float,
                       plugin: str = 'none', replay_buf: Optional[ReplayBuffer]=None,
                       ewc_state: Optional[dict]=None, teacher: Optional[TiSASRec]=None,
                       replay_ratio: float = 0.3, lwf_T: float = 2.0, lwf_alpha: float = 0.5,
                       E0=None, ids_t=None, lambda_anchor: float = 0.0):
    """
    支持：裸 TiSASRec 或 PeftModel(TiSASRec)。接口保持一致。
    """
    model.train()
    losses = []
    for batch in tqdm(ft_loader, desc='Finetune(F)', leave=False):
        seq = batch['seq'].to(device)
        t_bk = batch['t_buckets'].to(device)
        attn_mask = batch['attn_mask'].to(device)
        labels = batch['labels'].to(device)
        seqlen = batch['seqlen'].to(device)

        # Base CE on finetune window
        h = model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=pad_id)
        logits = model.predict_last(h, seqlen)
        logits = _masked_item_logits(logits, item_token_ids)
        loss = F.cross_entropy(logits, labels, ignore_index=-100)

        if (lambda_anchor > 0.0) and (E0 is not None) and (ids_t is not None) and ids_t.numel() > 0:
            emb = model.base_model.item_emb if hasattr(model, "base_model") else model.item_emb
            reg = (emb.weight.index_select(0, ids_t) - E0.index_select(0, ids_t)).pow(2).mean()
            loss = loss + lambda_anchor * reg

        # Replay: mix O-batch损失
        if ('replay' in plugin) and (replay_buf is not None):
            rb = replay_buf.next_batch()
            rseq = rb['seq'].to(device)
            rt_bk = rb['t_buckets'].to(device)
            rattn = rb['attn_mask'].to(device)
            rlabels = rb['labels'].to(device)
            rlen = rb['seqlen'].to(device)

            rh = model(rseq, rattn, rt_bk, pad_id)
            rlogits = model.predict_last(rh, rlen)
            rlogits = _masked_item_logits(rlogits, item_token_ids)
            replay_loss = F.cross_entropy(rlogits, rlabels, ignore_index=-100)
            loss = (1.0 - replay_ratio) * loss + replay_ratio * replay_loss

        # LwF: teacher KD on {pos, neg}
        if ('lwf' in plugin) and (teacher is not None):
            kd = lwf_kd_loss_tisasrec(model, teacher, batch={k:v.to(device) for k,v in batch.items() if torch.is_tensor(v)},
                                      pad_id=pad_id, item_token_ids=item_token_ids,
                                      T=lwf_T, alpha=lwf_alpha)
            loss = loss + kd

        # EWC（五模式不启用，但保留接口）
        if ('ewc' in plugin) and (ewc_state is not None):
            loss = loss + ewc_loss(model, ewc_state['fisher'], ewc_state['prev_params'], ewc_state['lam'])

        optimizer.zero_grad(set_to_none=True); loss.backward()
        if grad_clip and grad_clip > 0: clip_grad_norm_(model.parameters(), grad_clip)
        optimizer.step()
        if scheduler is not None: scheduler.step()
        losses.append(float(loss.detach().item()))
    return np.mean(losses) if losses else 0.0


@torch.no_grad()
def evaluate(model: nn.Module, loader: DataLoader, device, pad_id, item_token_ids, topk):
    model.eval()
    sumd = {k:{'hit':0.0,'dcg':0.0} for k in topk}; N = 0
    for batch in tqdm(loader, desc='Eval', leave=False):
        seq = batch['seq'].to(device)
        t_bk = batch['t_buckets'].to(device)
        attn_mask = batch['attn_mask'].to(device)
        labels = batch['labels'].to(device)
        seqlen = batch['seqlen'].to(device)

        h = model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=pad_id)
        logits = model.predict_last(h, seqlen)
        sums, bsz = recall_ndcg_sums(logits, labels, item_token_ids, topk=tuple(topk))
        for K in sums:
            sumd[K]['hit'] += sums[K]['hit']
            sumd[K]['dcg'] += sums[K]['dcg']
        N += bsz
    return aggregate_metrics(sumd, N, topk=tuple(topk))


# ======================================================================
# =====================  RAIE plugin (Region-Aware)  ====================
# ======================================================================

def l2_normalize(X: np.ndarray, eps: float = 1e-12):
    n = np.linalg.norm(X, axis=1, keepdims=True) + eps
    return (X / n).astype(np.float32)

def spherical_kmeans(X: np.ndarray, K: int, niter=30, seed=42):
    try:
        import faiss
        km = faiss.Kmeans(d=X.shape[1], k=K, niter=niter, nredo=2,
                          verbose=True, spherical=True, seed=seed)
        km.train(X.astype(np.float32))
        C = km.centroids.astype(np.float32)
        index = faiss.IndexFlatIP(X.shape[1]); index.add(C)
        _, lab = index.search(X, 1)
        return C, lab.reshape(-1).astype(np.int32)
    except Exception:
        from sklearn.cluster import KMeans
        skm = KMeans(n_clusters=K, n_init=10, max_iter=300, random_state=seed)
        lab = skm.fit_predict(X)
        C = l2_normalize(skm.cluster_centers_)
        return C.astype(np.float32), lab.astype(np.int32)

def per_cluster_radius(X, C, labels, q=0.9):
    K = C.shape[0]; R = np.zeros(K, np.float32)
    for k in range(K):
        idx = np.where(labels == k)[0]
        if len(idx) == 0: continue
        dots = X[idx] @ C[k]
        ang = np.arccos(np.clip(dots, -1, 1))
        R[k] = np.quantile(ang, q).astype(np.float32)
    return R

def per_cluster_ang_std(X, C, labels):
    K = C.shape[0]; sig = np.zeros(K, np.float32)
    for k in range(K):
        idx = np.where(labels == k)[0]
        if len(idx) == 0: continue
        dots = X[idx] @ C[k]
        ang = np.arccos(np.clip(dots, -1, 1))
        sig[k] = ang.std().astype(np.float32)
    return sig

def enforce_separation(C: np.ndarray, R: np.ndarray, eps_margin=0.03, iters=1):
    K = C.shape[0]
    for _ in range(iters):
        changed = False
        for i in range(K):
            for j in range(i+1, K):
                a = float(np.arccos(np.clip(C[i] @ C[j], -1, 1)))
                limit = max(0.0, a - eps_margin)
                s = R[i] + R[j]
                if s > limit and s > 1e-8:
                    scale = limit / s
                    R[i] *= scale; R[j] *= scale
                    changed = True
        if not changed: break
    return R

@torch.no_grad()
def encode_prompts_to_vecs_tisasrec(model: nn.Module, dataset: Dataset, collate_fn,
                                    pad_id: int, device, batch_size=256, use_mean_pool=True, pbar=False):
    """
    用 TiSASRec 的隐状态对 (prompt -> target) 的 prompt 做表征。
    """
    dl = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)
    vecs = []
    model.eval()
    for batch in tqdm(dl, desc='RAIE/Encode', disable=not pbar):
        seq = batch['seq'].to(device)
        t_bk = batch['t_buckets'].to(device)
        attn_mask = batch['attn_mask'].to(device)
        seqlen = batch['seqlen'].to(device)
        h = model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=pad_id)  # (B,L,D)

        if use_mean_pool:
            valid = (seq != pad_id).unsqueeze(-1).float()  # (B,L,1)
            v = (h * valid).sum(dim=1) / valid.sum(dim=1).clamp(min=1.0)  # (B,D)
        else:
            rows = torch.arange(seq.size(0), device=device)
            last_idx = (seqlen - 1).clamp(min=0)
            v = h[rows, last_idx, :]  # (B,D)
        vecs.append(v.detach().float().cpu().numpy())
    X = np.concatenate(vecs, axis=0).astype(np.float32)
    return l2_normalize(X)

class RegionBankTiSAS:
    """
    将 RAIE 逻辑封装为 TiSASRec 的插件：
      - original 上做聚类，统计 vMF 先验（mu/kappa/pi）
      - finetune 样本路由 Update/Expand/Add
      - 每个 region 训练专属 LoRA（混入对应 original 样本 + 边界软样本）
      - 测试时按后验分数路由到 region 适配器做预测
    """
    def __init__(self, model: nn.Module, pad_id: int, item_token_ids: List[int],
                 collate_fn, original_ds: Dataset,
                 out_dir: str, device,
                 lora_target_modules: List[str],
                 lora_r=8, lora_alpha=16, lora_dropout=0.05,
                 K=10, q=0.9, beta_post=8.0, delta_min=0.05,
                 n0=5.0, kappa_ema=0.2, lam_new=-1.0):
        self.model = model
        self.pad_id = pad_id
        self.item_token_ids = item_token_ids
        self.collate = collate_fn
        self.original_ds = original_ds
        self.device = device
        self.out_dir = out_dir

        # clustering / posterior
        self.K = K; self.q = q
        self.beta_post = beta_post
        self.delta_min = delta_min
        self.n0 = n0
        self.kappa_ema = kappa_ema
        self.lam_new = lam_new

        # LoRA config
        self.lora_cfg = LoraConfig(
            r=lora_r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,
            bias="none", task_type=TaskType.FEATURE_EXTRACTION, inference_mode=False,
            target_modules=lora_target_modules
        )

        # state
        self.C = None; self.R = None; self.sig = None
        self.C0 = None
        self.S = None; self.n = None
        self.kappa = None; self.pi = None
        self.orig_idx_by_k = {}

    # ---------- clustering on original ----------
    def fit_regions_on_original(self, seed=42):
        X = encode_prompts_to_vecs_tisasrec(self.model, self.original_ds, self.collate,
                                            self.pad_id, self.device, pbar=True)
        C, labels = spherical_kmeans(X, self.K, niter=30, seed=seed)
        R = per_cluster_radius(X, C, labels, q=self.q)
        sig = per_cluster_ang_std(X, C, labels)
        self.C, self.R, self.sig = C, R, sig
        self.C0 = C.copy()
        self._init_vmf_from_labels(X, labels)

        # save original index buckets
        self.orig_idx_by_k = {k: [] for k in range(self.K)}
        for i, k in enumerate(labels):
            self.orig_idx_by_k[int(k)].append(i)

        np.savez(os.path.join(self.out_dir, "raie_regions_init.npz"),
                 centroids=C, radii=R, sig=sig, K=self.K, dim=C.shape[1])
        return labels

    def _init_vmf_from_labels(self, X, labels):
        K, H = self.C.shape[0], X.shape[1]
        self.S = np.zeros((K, H), np.float32)
        self.n = np.zeros((K,), np.float32)
        for i, k in enumerate(labels.astype(int)):
            self.S[k] += X[i]; self.n[k] += 1.0
        self._recompute_mu_kappa_pi()

    def _recompute_mu_kappa_pi(self):
        eps = 1e-12
        self._sync_priors_shape()

        # S_hat = S + n0 * C0
        S_hat = self.S + self.n0 * self.C0
        n_hat = self.n + self.n0

        normS = np.linalg.norm(S_hat, axis=1, keepdims=True) + eps
        C_new = (S_hat / normS).astype(np.float32)

        d = C_new.shape[1]
        r = (normS.squeeze(-1)) / np.maximum(n_hat, 1e-6)
        # 数值安全：r ∈ (0,1)
        r = np.clip(r, 1e-6, 1 - 1e-6)
        kappa_new = (r * (d - r ** 2)) / np.clip(1.0 - r ** 2, 1e-6, None)
        kappa_new = np.clip(kappa_new, 1.0, 1e6).astype(np.float32)

        K = C_new.shape[0]
        if self.kappa is None:
            self.kappa = kappa_new
        else:
            if self.kappa.shape[0] != K:
                new_kappa = np.zeros_like(kappa_new, dtype=np.float32)
                n_old = min(self.kappa.shape[0], K)
                new_kappa[:n_old] = self.kappa[:n_old]
                new_kappa[n_old:] = kappa_new[n_old:]
                self.kappa = new_kappa
            # 再做 EMA
            self.kappa = (1.0 - self.kappa_ema) * self.kappa + self.kappa_ema * kappa_new

        nsum = float(np.maximum(n_hat.sum(), 1.0))
        self.pi = (n_hat / nsum).astype(np.float32)
        self.C = C_new

    def _sync_priors_shape(self):
        """
        Ensure C0 (prior centroids) has the same (K, H) shape as current S/C.
        - When clusters were added: append current C rows for the new indices.
        - When clusters were merged: truncate C0 accordingly.
        Also keep R/sig in-sync when size changes (if they exist).
        """
        K, H = self.S.shape  # current K
        if self.C0 is None:
            # first time: use current C as prior
            self.C0 = self.C.copy().astype(np.float32)

        if self.C0.shape[0] < K:
            # 用新增 S 行的方向来补 C0，而不是用尚未扩容的 self.C
            S_ex = self.S[self.C0.shape[0]:K, :]  # 形状 (K-C0, H)
            norms = np.linalg.norm(S_ex, axis=1, keepdims=True)
            safe = (norms > 1e-12).astype(np.float32)
            extra = np.zeros_like(S_ex, dtype=np.float32)
            if safe.sum() > 0:
                extra[safe.squeeze(-1) > 0] = (S_ex[safe.squeeze(-1) > 0] /
                                               (norms[safe.squeeze(-1) > 0] + 1e-12)).astype(np.float32)
            # fallback：如果某些行全零，用当前 C 的均值方向
            if np.any(~np.isfinite(extra)) or (safe.sum() < (K - self.C0.shape[0])):
                mean_mu = np.mean(self.C, axis=0, keepdims=True)
                mean_mu = mean_mu / (np.linalg.norm(mean_mu, axis=1, keepdims=True) + 1e-12)
                for r in range(extra.shape[0]):
                    if not np.isfinite(extra[r]).all() or np.linalg.norm(extra[r]) < 1e-9:
                        extra[r] = mean_mu.astype(np.float32)
            self.C0 = np.vstack([self.C0, extra])
        elif self.C0.shape[0] > K:
            self.C0 = self.C0[:K, :]

        # Keep R and sig length in-sync too (safe defaults for new clusters)
        def _ensure_vec_len(vec, fill_val):
            if vec is None:
                return np.full((K,), fill_val, dtype=np.float32)
            if vec.shape[0] < K:
                extra = np.full((K - vec.shape[0],), fill_val, dtype=np.float32)
                return np.concatenate([vec, extra], axis=0)
            elif vec.shape[0] > K:
                return vec[:K]
            return vec

        med_R = float(np.median(self.R)) if (self.R is not None and self.R.size > 0) else np.deg2rad(15.0)
        med_sig = float(np.median(self.sig)) if (self.sig is not None and self.sig.size > 0) else np.deg2rad(8.0)
        self.R = _ensure_vec_len(self.R, med_R)
        self.sig = _ensure_vec_len(self.sig, med_sig)

    def _scores_post(self, x: np.ndarray):
        sims = self.C @ x  # [K]
        scores = np.log(np.clip(self.pi, 1e-8, None)) + self.kappa * sims
        top2 = np.argsort(scores)[-2:]
        k2, k1 = int(top2[0]), int(top2[1])
        s1, s2 = float(scores[k1]), float(scores[k2])
        z = scores - scores.max()
        p = np.exp(self.beta_post * z); p = p / (p.sum() + 1e-8)
        return k1, k2, s1, s2, float(p[k1]), float(p[k2])

    def _tau_assign(self, k: int, a0: float = 0.5, a1: float = 0.1):
        return 1.0 / (1.0 + np.exp(-(a0 + a1 * np.log(self.kappa[k] + 1e-6))))

    def _decide_action(self, x: np.ndarray):
        k1, k2, s1, s2, p1, p2 = self._scores_post(x)
        tau1 = self._tau_assign(k1)
        if s1 < self.lam_new and p1 < tau1 * 0.7:
            return ("add", k1, k2, p1, p2)
        if p1 >= tau1 and (p1 - p2) >= self.delta_min:
            return ("update", k1, k2, p1, p2)
        if p1 >= tau1:
            return ("expand", k1, k2, p1, p2)
        return ("add", k1, k2, p1, p2)

    # ---------- finetune mapping ----------
    def map_finetune(self, finetune_ds: Dataset, pool_min=200, bic_gain=1e4):
        Xn = encode_prompts_to_vecs_tisasrec(self.model, finetune_ds, self.collate,
                                             self.pad_id, self.device, pbar=True)
        from collections import defaultdict
        buckets = defaultdict(list)
        add_pool = []
        soft_pairs = []

        for i in range(Xn.shape[0]):
            x = Xn[i]
            act, k1, k2, p1, p2 = self._decide_action(x)
            if act == "update":
                buckets[k1].append(i)
                self.S[k1] += x; self.n[k1] += 1.0
            elif act == "expand":
                buckets[k1].append(i)
                s = p1 + p2 + 1e-8
                w1, w2 = p1 / s, p2 / s
                soft_pairs.append((i, k1, k2, float(w1), float(w2)))
                self.S[k1] += 0.25 * x; self.n[k1] += 0.25
            else:
                add_pool.append((i, k1))
                soft_pairs.append((i, k1, k2, 0.3, 0.0))

        self._recompute_mu_kappa_pi()

        # 试建新簇（简化）
        if len(add_pool) >= pool_min:
            add_idx = [idx for (idx, _k1) in add_pool]
            Xp = Xn[add_idx]
            centers = self._propose_new_centers(Xp, max_new=2)
            if self._accept_new_clusters(Xp, centers, bic_gain=bic_gain):
                for mu_new in centers:
                    self.S = np.vstack([self.S, mu_new[None, :]])
                    self.n = np.append(self.n, 1.0)
                self._recompute_mu_kappa_pi()
                new_start = self.C.shape[0] - len(centers)
                sims = Xp @ np.stack(centers, 0).T
                assign = np.argmax(sims, axis=1)
                for j, idx in enumerate(add_idx):
                    buckets[new_start + int(assign[j])].append(idx)
                add_pool.clear()
            else:
                for idx, near_k1 in add_pool:
                    buckets[near_k1].append(idx)
                add_pool.clear()
        else:
            for idx, near_k1 in add_pool:
                buckets[near_k1].append(idx)
            add_pool.clear()

        self._maybe_merge_by_angle(angle_thr=np.deg2rad(12), max_pairs=1)

        np.savez(os.path.join(self.out_dir, "raie_regions_after_map.npz"),
                 centroids=self.C, radii=self.R, sig=self.sig,
                 kappa=self.kappa, pi=self.pi, S=self.S, n=self.n)
        return buckets, soft_pairs

    def _propose_new_centers(self, Xp: np.ndarray, max_new=2):
        cand = []
        if Xp.shape[0] == 0: return cand
        mu1 = Xp.mean(0); mu1 /= (np.linalg.norm(mu1) + 1e-12)
        cand.append(mu1.astype(np.float32))
        if Xp.shape[0] >= 50 and max_new >= 2:
            C2, _ = spherical_kmeans(Xp, 2, niter=20, seed=42)
            cand.extend([C2[0], C2[1]])
        return cand[:max_new]

    def _accept_new_clusters(self, Xp: np.ndarray, centers: List[np.ndarray], bic_gain=1e4) -> bool:
        if len(centers) == 0 or Xp.shape[0] == 0: return False
        sims_old = Xp @ self.C.T
        scores_old = np.log(np.clip(self.pi, 1e-8, None))[None, :] + sims_old * self.kappa[None, :]
        ll_old = float(np.max(scores_old, axis=1).sum())

        def _est_kappa(mu):
            dots = Xp @ mu
            rbar = float(np.mean(np.clip(dots, -1, 1)))
            d = Xp.shape[1]
            return max(1.0, min(1e6, (rbar * (d - rbar**2)) / max(1e-6, (1 - rbar**2))))

        addC = np.stack(centers, 0).astype(np.float32)
        kappa_new = np.array([_est_kappa(mu) for mu in addC], np.float32)
        sims_new = Xp @ addC.T
        score_new = sims_new * kappa_new[None, :]

        w = np.maximum(score_new.mean(0), 1e-6)
        w = w / (w.sum() + 1e-8)
        eps = 0.10  # 可调
        all_mu = np.vstack([self.C, addC])
        all_kappa = np.concatenate([self.kappa, kappa_new])
        all_pi = np.concatenate([self.pi * (1 - eps), w * eps])
        all_pi = all_pi / (all_pi.sum() + 1e-8)

        sims_all = Xp @ all_mu.T
        scores_all = np.log(np.clip(all_pi, 1e-8, None))[None, :] + sims_all * all_kappa[None, :]
        ll_new = float(np.max(scores_all, axis=1).sum())

        d = Xp.shape[1]
        K0 = self.C.shape[0]; K1 = K0 + len(centers)
        bic_old = ll_old - 0.5 * (K0 * d) * np.log(Xp.shape[0] + 1e-8)
        bic_new = ll_new - 0.5 * (K1 * d) * np.log(Xp.shape[0] + 1e-8)
        return (bic_new - bic_old) > bic_gain

    def _maybe_merge_by_angle(self, angle_thr=np.deg2rad(12), max_pairs=1):
        K = self.C.shape[0]
        if K <= 1: return
        pairs = []
        for i in range(K):
            for j in range(i+1, K):
                ang = np.arccos(np.clip(self.C[i] @ self.C[j], -1, 1))
                if ang < angle_thr: pairs.append((ang, i, j))
        pairs.sort()
        merged = 0
        for _, i, j in pairs:
            if i >= self.C.shape[0] or j >= self.C.shape[0]: continue
            Sij = self.S[i] + self.S[j]; nij = self.n[i] + self.n[j]
            self.S[i] = Sij; self.n[i] = nij
            self.S = np.delete(self.S, j, axis=0)
            self.n = np.delete(self.n, j, axis=0)
            self.C = np.delete(self.C, j, axis=0)
            if self.kappa is not None: self.kappa = np.delete(self.kappa, j, axis=0)
            if self.pi is not None: self.pi = np.delete(self.pi, j, axis=0)
            merged += 1
            if merged >= max_pairs: break
        self._recompute_mu_kappa_pi()

    # ---------- region LoRA training ----------
    def _ensure_adapter(self, adapter_name: str):
        if adapter_name in getattr(self.model, "peft_config", {}):
            return
        default_dir = os.path.join(self.out_dir, "adapter_default")
        if os.path.isdir(default_dir):
            self.model.load_adapter(default_dir, adapter_name=adapter_name, is_trainable=True)
        else:
            self.model.add_adapter(adapter_name, self.lora_cfg)

    def train_regions(self, finetune_ds: Dataset, finetune_collate,
                      optimizer_ctor, scheduler_ctor,
                      epochs_per_region=2, batch_size=256, orig_mix_ratio=0.3,
                      region_buckets: Dict[int, List[int]] = None,
                      soft_pairs: Optional[List[Tuple[int,int,int,float,float]]] = None,
                      soft_rep_factor: int = 2, seed: int = 42):
        assert region_buckets is not None
        soft_pairs = soft_pairs or []
        from collections import defaultdict
        soft_idx_by_k = defaultdict(list)
        for (i, k1, k2, w1, w2) in soft_pairs:
            if w1 > 0:
                soft_idx_by_k[k1].extend([i] * max(0, int(round(w1 * soft_rep_factor))))
            if w2 > 0:
                soft_idx_by_k[k2].extend([i] * max(0, int(round(w2 * soft_rep_factor))))

        no_decay = ['bias', 'LayerNorm.weight']

        for k, idx_list in sorted(region_buckets.items(), key=lambda kv: -len(kv[1])):
            if len(idx_list) == 0: continue
            name = f"region_{k}"
            self._ensure_adapter(name)
            self.model.set_adapter(name)
            if hasattr(self.model, "train_adapter"): self.model.train_adapter(name)
            self.model.train()

            ft_subset = Subset(finetune_ds, idx_list)

            if (k in self.orig_idx_by_k) and (orig_mix_ratio > 0) and (self.original_ds is not None):
                orig_idx = self.orig_idx_by_k[k]
                n_ft = len(ft_subset)
                n_orig = int(round(n_ft * orig_mix_ratio / max(1e-8, 1.0 - orig_mix_ratio)))
                if n_orig > 0 and len(orig_idx) > 0:
                    rng = np.random.RandomState(seed)
                    sel = rng.choice(orig_idx, size=min(n_orig, len(orig_idx)), replace=False)
                    orig_subset = Subset(self.original_ds, sel)
                    base_ds = ConcatDataset([ft_subset, orig_subset])
                else:
                    base_ds = ft_subset
            else:
                base_ds = ft_subset

            if len(soft_idx_by_k[k]) > 0:
                soft_subset = Subset(finetune_ds, soft_idx_by_k[k])
                train_ds = ConcatDataset([base_ds, soft_subset])
            else:
                train_ds = base_ds

            dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0,
                            collate_fn=finetune_collate)
            optim = optimizer_ctor(self.model)
            sched = scheduler_ctor(optim, len(dl), epochs_per_region)

            for ep in range(epochs_per_region):
                pbar = tqdm(dl, desc=f"[RAIE][Region {k}] Ep {ep+1}/{epochs_per_region}")
                for batch in pbar:
                    seq = batch['seq'].to(self.device)
                    t_bk = batch['t_buckets'].to(self.device)
                    attn_mask = batch['attn_mask'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    seqlen = batch['seqlen'].to(self.device)

                    out_h = self.model(seq_ids=seq, attn_mask=attn_mask, t_buckets=t_bk, pad_id=self.pad_id)
                    logits = self.model.predict_last(out_h, seqlen)

                    V = logits.size(-1)
                    mask = torch.full((V,), float('-inf'), device=self.device)
                    mask[self.item_token_ids] = 0.0
                    logits = logits + mask

                    loss = F.cross_entropy(logits, labels, ignore_index=-100)

                    optim.zero_grad(set_to_none=True)
                    loss.backward()
                    optim.step(); sched.step()
                    pbar.set_postfix({"loss": float(loss.detach().cpu())})

            save_dir = os.path.join(self.out_dir, f"adapter_region_{k}")
            os.makedirs(save_dir, exist_ok=True)
            try:
                self.model.save_pretrained(save_dir, selected_adapters=[name])
            except Exception:
                torch.save({'peft': {n:v for n,v in self.model.state_dict().items() if 'lora_' in n}} ,
                           os.path.join(save_dir, 'lora_only.pt'))

    # ---------- routing eval ----------
    @torch.no_grad()
    def route_and_eval(self, test_ds: Dataset, collate_fn, pad_id: int, item_token_ids: List[int],
                       eval_fn, k_list=(5,10,20), batch_size=256):
        X = encode_prompts_to_vecs_tisasrec(self.model, test_ds, collate_fn,
                                            pad_id, self.device, batch_size=batch_size, pbar=True)
        sims = X @ self.C.T
        scores = np.log(np.clip(self.pi, 1e-8, None))[None, :] + sims * self.kappa[None, :]
        route_k = np.argmax(scores, axis=1)

        from collections import defaultdict
        idx_by_k = defaultdict(list)
        for i, k in enumerate(route_k): idx_by_k[int(k)].append(i)

        all_stats = []
        for k in sorted(idx_by_k.keys()):
            name = f"region_{k}"
            adapter_dir = os.path.join(self.out_dir, f"adapter_region_{k}", f"{name}")
            if os.path.isdir(adapter_dir) and (name not in getattr(self.model, "peft_config", {})):
                self.model.load_adapter(adapter_dir, adapter_name=name, is_trainable=False)
            self.model.set_adapter(name if name in getattr(self.model, "peft_config", {}) else "default")

            sub = Subset(test_ds, idx_by_k[k])
            dl = DataLoader(sub, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)
            stat = eval_fn(self.model, dl, self.device, pad_id, item_token_ids, k_list)
            stat["cluster_id"] = int(k); stat["num_samples"] = len(sub)
            all_stats.append(stat)
        return all_stats


# ------------------------------
# Main
# ------------------------------

def main():
    ap = argparse.ArgumentParser()
    # 新增：五模式开关
    ap.add_argument('--mode', type=str, default='raie',
                    choices=['base', 'lora', 'lora_replay', 'lora_lwf', 'raie'],
                    help='五种方式：base / lora / lora_replay / lora_lwf / raie')

    ap.add_argument('--data_dir', type=str, default='/home/zj/code/Amazon_electronics/')
    ap.add_argument('--output_dir', type=str, default='./runs/TiSASRec_Amazon_electronics')

    ap.add_argument('--max_len', type=int, default=50)
    ap.add_argument('--hidden_size', type=int, default=256)
    ap.add_argument('--layers', type=int, default=2)
    ap.add_argument('--heads', type=int, default=4)
    ap.add_argument('--ffn_size', type=int, default=1024)
    ap.add_argument('--dropout', type=float, default=0.2)

    ap.add_argument('--time_unit', type=str, default='seconds', choices=['seconds','minutes','hours','days'])
    ap.add_argument('--time_bucket', type=int, default=64)
    ap.add_argument('--time_clamp', type=int, default=60, help='Clamp intervals > N days to last bucket; set -1 to disable')
    ap.add_argument('--train_stride', type=int, default=1)
    ap.add_argument('--min_ctx', type=int, default=1)
    ap.add_argument('--batch_size', type=int, default=512)
    ap.add_argument('--epochs', type=int, default=5)
    ap.add_argument('--lr', type=float, default=5e-4)
    ap.add_argument('--weight_decay', type=float, default=0.0)
    ap.add_argument('--warmup_ratio', type=float, default=0.1)
    ap.add_argument('--grad_clip', type=float, default=1.0)
    ap.add_argument('--seed', type=int, default=42)

    # Stage-F
    ap.add_argument('--finetune_epochs', type=int, default=3)
    ap.add_argument('--finetune_batch_size', type=int, default=512)
    ap.add_argument('--finetune_lr', type=float, default=5e-4)

    # Plugins（五模式里只用 replay / lwf；保留 ewc 参数但不走该分支）
    ap.add_argument('--plugin', type=str, default='none',
                    choices=['none','replay','ewc','lwf','replay+ewc','lwf+ewc','replay+lwf','replay+lwf+ewc'])
    ap.add_argument('--replay_ratio', type=float, default=0.3)
    ap.add_argument('--ewc_lambda', type=float, default=5.0)
    ap.add_argument('--ewc_max_batches', type=int, default=100)
    ap.add_argument('--lwf_T', type=float, default=2.0)
    ap.add_argument('--lwf_alpha', type=float, default=0.5)

    ap.add_argument('--topk', type=str, default='5,10,20')

    # ---- LoRA args ----
    ap.add_argument('--use_lora', default=True)
    ap.add_argument('--lora_r', type=int, default=8)
    ap.add_argument('--lora_alpha', type=int, default=16)
    ap.add_argument('--lora_dropout', type=float, default=0.05)
    ap.add_argument('--lora_target', type=str,
                    default='Wq,Wk,Wv,Wo,ffn.0,ffn.3',
                    help='逗号分隔的模块名（支持子串匹配），例如 "Wq,Wk,Wv,Wo,ffn.0,ffn.3"')

    # ===== RAIE plugin switches =====
    ap.add_argument('--raie_enable', action='store_true', default=True, help='启用 RAIE 区域化 LoRA 插件')
    ap.add_argument('--raie_K', type=int, default=3)
    ap.add_argument('--raie_q', type=float, default=0.9)
    ap.add_argument('--raie_pool_min', type=int, default=120)
    ap.add_argument('--raie_epochs_per_region', type=int, default=2)
    ap.add_argument('--raie_orig_mix_ratio', type=float, default=0.3)
    ap.add_argument('--raie_soft_rep_factor', type=int, default=2)
    ap.add_argument('--raie_beta_post', type=float, default=8.0)
    ap.add_argument('--raie_delta_min', type=float, default=0.05)
    ap.add_argument('--raie_n0', type=float, default=5.0)
    ap.add_argument('--raie_kappa_ema', type=float, default=0.2)
    ap.add_argument('--raie_lam_new', type=float, default=-1.0)

    # 可选护栏：是否允许“全参微调”触发 Stage-F（默认为 False，用于 base 模式避免误触）
    ap.add_argument('--enable_full_finetune', action='store_true', default=False)

    args = ap.parse_args()

    # ---------- 五模式到内部开关的映射（不改变模块内逻辑，只调流程） ----------
    # 统一禁用 EWC（你的五模式不包含）；RAIE 独立由 raie_enable 控制
    if args.mode == 'base':
        args.use_lora = False
        args.plugin = 'none'
        args.raie_enable = False
    elif args.mode == 'lora':
        args.use_lora = True
        args.plugin = 'none'
        args.raie_enable = False
    elif args.mode == 'lora_replay':
        args.use_lora = True
        args.plugin = 'replay'
        args.raie_enable = False
    elif args.mode == 'lora_lwf':
        args.use_lora = True
        args.plugin = 'lwf'
        args.raie_enable = False
    elif args.mode == 'raie':
        args.use_lora = True
        args.plugin = 'none'   # RAIE 自己走 Stage-R
        args.raie_enable = True

    if args.use_lora and (not PEFT_AVAILABLE):
        raise RuntimeError(f"peft not available: {_PEFT_ERR}")

    os.makedirs(args.output_dir, exist_ok=True)
    set_seed(args.seed)

    # Vocab
    token2id, id2token, item_token_ids = load_item_vocab(args.data_dir)
    pad_id = token2id['[PAD]']

    # Data
    train_path = os.path.join(args.data_dir, 'original_stream.jsonl')
    original_path = os.path.join(args.data_dir, 'original_stride1.jsonl')
    finetune_path = os.path.join(args.data_dir, 'finetune.jsonl')
    test_path = os.path.join(args.data_dir, 'test.jsonl')
    if not (os.path.exists(train_path) and os.path.exists(test_path)):
        raise FileNotFoundError('Missing original_stream.jsonl or test.jsonl in data_dir')

    train_ds = StreamPairDataset(train_path, stride=args.train_stride, min_ctx=args.min_ctx)
    original_ds = SeqDataset(original_path) if os.path.exists(original_path) else None
    finetune_ds = SeqDataset(finetune_path) if os.path.exists(finetune_path) else None
    test_ds = SeqDataset(test_path)

    clamp_days = None if args.time_clamp is None or args.time_clamp < 0 else args.time_clamp
    bucketizer = TimeBucketizer(args.time_unit, args.time_bucket, clamp_days)
    collate = Collator(token2id, args.max_len, pad_id, bucketizer, item_token_ids)

    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=2, collate_fn=collate)
    test_loader  = DataLoader(test_ds,  batch_size=args.batch_size, shuffle=False, num_workers=2, collate_fn=collate)

    # Model
    vocab_size = len(id2token)
    base_model = TiSASRec(n_items=vocab_size, d_model=args.hidden_size, n_layers=args.layers,
                          n_heads=args.heads, d_ff=args.ffn_size, dropout=args.dropout,
                          max_len=args.max_len, n_time_buckets=args.time_bucket)

    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')

    base_model.to(device)

    # Optim for O-stage
    no_decay = ['bias', 'LayerNorm.weight']
    params = [
        {'params':[p for n,p in base_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},
        {'params':[p for n,p in base_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},
    ]
    optimizer = torch.optim.AdamW(params, lr=args.lr)

    total_steps = len(train_loader) * max(args.epochs,1)
    warmup_steps = int(total_steps * args.warmup_ratio)
    scheduler = torch.optim.lr_scheduler.LambdaLR(
        optimizer,
        lr_lambda=lambda step: min((step+1)/max(1,warmup_steps), 1.0)
    )

    # ===== Stage O: Train base on original_stream.jsonl =====
    for ep in range(1, args.epochs+1):
        tr_loss = train_one_epoch(base_model, train_loader, optimizer, scheduler, device, pad_id, item_token_ids, args.grad_clip)
        print(f"[O][Epoch {ep}] train_loss={tr_loss:.4f}")

    # Save base (optional)
    torch.save({'model': base_model.state_dict(), 'vocab': id2token, 'cfg': vars(args)},
               os.path.join(args.output_dir, 'base_model.pt'))
    print('Saved base model to', os.path.join(args.output_dir, 'base_model.pt'))

    # ----- Prepare plugins (computed on base) -----
    replay_buf = ReplayBuffer(train_ds, collate,
                              batch_size=args.finetune_batch_size) if (args.plugin.startswith('replay')) else None

    teacher = None
    if args.plugin == 'lwf':
        teacher = TiSASRec(n_items=vocab_size, d_model=args.hidden_size, n_layers=args.layers,
                           n_heads=args.heads, d_ff=args.ffn_size, dropout=args.dropout,
                           max_len=args.max_len, n_time_buckets=args.time_bucket).to(device)
        teacher.load_state_dict(base_model.state_dict(), strict=True)
        for p in teacher.parameters(): p.requires_grad = False
        teacher.eval()

    # ========== Stage F：按模式选择是否进行 ==========
    model = base_model
    did_f_stage = False

    # base 模式严格不做任何微调；其它模式若 use_lora=True 则进行 LoRA 微调
    if (args.mode != 'base') and args.use_lora and finetune_ds is not None and len(finetune_ds) > 0:
        # —— 收集 F 段涉及的 item 行（target 中出现且确为 item 的 token）——
        ft_item_ids = sorted({
            token2id.get(ex.target_token, None)
            for ex in finetune_ds.examples
            if token2id.get(ex.target_token, None) in item_token_ids
        })
        ids_t = torch.tensor(ft_item_ids, device=device) if len(ft_item_ids) > 0 else None

        # —— 拍一个 item_emb 的快照（锚点）——
        E0 = base_model.item_emb.weight.detach().clone()

        # LoRA 包裹
        target_modules = [s.strip() for s in args.lora_target.split(',') if s.strip()]
        lora_cfg = LoraConfig(
            r=args.lora_r,
            lora_alpha=args.lora_alpha,
            lora_dropout=args.lora_dropout,
            bias='none',
            task_type=TaskType.FEATURE_EXTRACTION,
            target_modules=target_modules,
        )
        model = get_peft_model(base_model, lora_cfg).to(device)
        try:
            model.print_trainable_parameters()
        except Exception:
            pass

        FT_loader = DataLoader(finetune_ds, batch_size=args.finetune_batch_size, shuffle=True, num_workers=2,
                               collate_fn=collate)

        # 只优化 LoRA 参数
        ft_params = [p for p in model.parameters() if p.requires_grad]
        ft_optim = torch.optim.AdamW(ft_params, lr=args.finetune_lr)

        ft_steps = len(FT_loader) * max(args.finetune_epochs, 1)
        ft_warm = int(ft_steps * args.warmup_ratio)
        ft_sched = torch.optim.lr_scheduler.LambdaLR(
            ft_optim, lr_lambda=lambda step: min((step + 1) / max(1, ft_warm), 1.0)
        )

        lambda_anchor = 1e-4
        plugin_flag = args.plugin  # 'none' / 'replay' / 'lwf'

        for ep in range(1, args.finetune_epochs + 1):
            ft_loss = finetune_one_epoch(model, FT_loader, ft_optim, ft_sched, device, pad_id, item_token_ids,
                                         args.grad_clip, plugin=plugin_flag, replay_buf=replay_buf,
                                         ewc_state=None, teacher=teacher, replay_ratio=args.replay_ratio,
                                         lwf_T=args.lwf_T, lwf_alpha=args.lwf_alpha, E0=E0, ids_t=ids_t, lambda_anchor=lambda_anchor)
            print(f"[F][Epoch {ep}] finetune_loss={ft_loss:.4f}")

        did_f_stage = True

        # 保存默认 LoRA 适配器（供 RAIE 或直接评测使用）
        lora_dir = os.path.join(args.output_dir, 'lora_adapter')
        os.makedirs(lora_dir, exist_ok=True)
        try:
            model.save_pretrained(lora_dir)
            print('Saved LoRA adapter to', lora_dir)
        except Exception as e:
            torch.save({'peft': {k: v for k, v in model.state_dict().items() if 'lora_' in k}} ,
                       os.path.join(lora_dir, 'lora_only.pt'))
            print('Saved LoRA state_dict to', os.path.join(lora_dir, 'lora_only.pt'))

        default_dir = os.path.join(args.output_dir, "adapter_default")
        os.makedirs(default_dir, exist_ok=True)
        try:
            model.save_pretrained(default_dir, selected_adapters=["default"])
            print('Saved default adapter to', default_dir)
        except Exception:
            pass

    # ===== Stage R: RAIE（仅 raie 模式） =====
    if args.mode == 'raie':
        if not (args.use_lora and PEFT_AVAILABLE):
            raise RuntimeError("[RAIE] 需要启用 LoRA 且 peft 可用。")
        if finetune_ds is None or len(finetune_ds) == 0:
            raise RuntimeError("[RAIE] 需要 finetune.jsonl。")
        if original_ds is None or len(original_ds) == 0:
            raise RuntimeError("[RAIE] 需要 original_stride1.jsonl（或自行准备同格式原始窗口数据）。")

        print("[RAIE] Enable region-aware incremental editing for TiSASRec.")
        target_modules = [s.strip() for s in args.lora_target.split(',') if s.strip()]
        bank = RegionBankTiSAS(
            model=model,
            pad_id=pad_id,
            item_token_ids=item_token_ids,
            collate_fn=collate,
            original_ds=original_ds,
            out_dir=args.output_dir,
            device=device,
            lora_target_modules=target_modules,
            lora_r=args.lora_r, lora_alpha=args.lora_alpha, lora_dropout=args.lora_dropout,
            K=args.raie_K, q=args.raie_q, beta_post=args.raie_beta_post,
            delta_min=args.raie_delta_min, n0=args.raie_n0, kappa_ema=args.raie_kappa_ema, lam_new=args.raie_lam_new
        )
        _ = bank.fit_regions_on_original(seed=args.seed)
        region_buckets, soft_pairs = bank.map_finetune(finetune_ds, pool_min=args.raie_pool_min)

        def _optim_ctor(m):
            groups = [
                {'params':[p for n,p in m.named_parameters() if p.requires_grad and not any(nd in n for nd in no_decay)], 'weight_decay': 0.0},
                {'params':[p for n,p in m.named_parameters() if p.requires_grad and any(nd in n for nd in no_decay)], 'weight_decay': 0.0},
            ]
            return torch.optim.AdamW([g for g in groups if len(g['params'])>0], lr=args.finetune_lr)

        def _sched_ctor(optim, steps_per_epoch, epochs):
            total = steps_per_epoch * epochs
            warm = int(total * args.warmup_ratio)
            return torch.optim.lr_scheduler.LambdaLR(
                optim, lr_lambda=lambda step: min((step + 1) / max(1, warm), 1.0)
            )

        bank.train_regions(
            finetune_ds=finetune_ds,
            finetune_collate=collate,
            optimizer_ctor=_optim_ctor,
            scheduler_ctor=_sched_ctor,
            epochs_per_region=args.raie_epochs_per_region,
            batch_size=args.finetune_batch_size,
            orig_mix_ratio=args.raie_orig_mix_ratio,
            region_buckets=region_buckets,
            soft_pairs=soft_pairs,
            soft_rep_factor=args.raie_soft_rep_factor,
            seed=args.seed
        )

        # 分区路由评测（打印加权全局）
        def _eval_fn(m, loader, device, pad_id, item_token_ids, topk_tuple):
            return evaluate(m, loader, device, pad_id, item_token_ids, list(topk_tuple))

        topk_tuple = tuple(int(x) for x in args.topk.split(','))
        stats = bank.route_and_eval(test_ds, collate, pad_id, item_token_ids,
                                    _eval_fn, k_list=topk_tuple, batch_size=args.finetune_batch_size)
        import pandas as pd
        df = pd.DataFrame(stats)
        if len(df) > 0:
            w = df["num_samples"].clip(lower=0)
            W = max(1, float(w.sum()))
            global_metrics = {m: float((df[m] * w).sum() / W) for m in df.columns if m.startswith(("Recall@", "NDCG@"))}
            print("[RAIE][Global]", global_metrics)
            try:
                with open(os.path.join(args.output_dir, "raie_test_global.json"), "w", encoding="utf-8") as f:
                    json.dump(global_metrics, f, ensure_ascii=False, indent=2)
                df.to_json(os.path.join(args.output_dir, "raie_test_by_cluster.json"), orient="records", force_ascii=False, indent=2)
            except Exception:
                pass
    else:
        if args.mode != 'base':
            print("[RAIE] Skipped (mode != raie).")

    try:
        model.set_adapter("default")
    except Exception:
        pass

    # ----- Eval：按五模式进行最终测试 -----
    topk = tuple(int(x) for x in args.topk.split(','))
    metrics = evaluate(model, test_loader, device, pad_id, item_token_ids, topk)
    pretty = ' '.join([f"{k}:{v:.4f}" for k,v in sorted(metrics.items())])
    print(f"[T][{args.mode}] {pretty}")

    with open(os.path.join(args.output_dir, f'test_metrics_{args.mode}.json'), 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)

    # 保存最终模型（含或不含 LoRA 包装）
    torch.save({'model': model.state_dict(), 'vocab': id2token, 'cfg': vars(args)},
               os.path.join(args.output_dir, f'model_final_{args.mode}.pt'))
    print('Saved to', args.output_dir)


if __name__ == '__main__':
    main()
